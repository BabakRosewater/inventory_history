name: Mirror dtfeed inventory (MP16607)

on:
  schedule:
    - cron: "0 */6 * * *"   # every 6 hours (UTC)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  mirror:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download feed (HTTP)
        run: |
          set -euo pipefail
          mkdir -p data/latest
          curl -L --fail "http://dtfeed.camclarkautogroup.com/ftp/MP16607.csv" -o data/latest/MP16607.csv

      - name: Build app-ready + age tracking
        run: |
          set -euo pipefail
          python3 scripts/build_app_ready.py

      - name: Snapshot + update index (only if feed changed)
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, json, gzip, shutil, hashlib
          from datetime import datetime, timezone

          latest_path = "data/latest/MP16607.csv"

          def sha256(p):
            h = hashlib.sha256()
            with open(p, "rb") as f:
              for chunk in iter(lambda: f.read(1024*1024), b""):
                h.update(chunk)
            return h.hexdigest()

          new_hash = sha256(latest_path)

          index_path = "data/index.json"
          index = {"feed":"MP16607","snapshots":[]}
          if os.path.exists(index_path):
            with open(index_path, "r", encoding="utf-8") as f:
              index = json.load(f)

          last_hash = index["snapshots"][0]["sha256"] if index["snapshots"] else None

          if new_hash == last_hash:
            print("No change in feed; skipping snapshot (but continuing).")
          else:
            ts = datetime.now(timezone.utc)
            yyyy, mm, dd = ts.strftime("%Y"), ts.strftime("%m"), ts.strftime("%d")
            stamp = ts.strftime("%Y%m%d_%H%M")
            folder = f"data/snapshots/{yyyy}/{mm}/{dd}"
            os.makedirs(folder, exist_ok=True)

            snap_csv = f"{folder}/MP16607_{stamp}.csv"
            shutil.copy2(latest_path, snap_csv)

            gz_path = snap_csv + ".gz"
            with open(snap_csv, "rb") as f_in, gzip.open(gz_path, "wb", compresslevel=6) as f_out:
              shutil.copyfileobj(f_in, f_out)
            os.remove(snap_csv)

            # count rows (minus header)
            with gzip.open(gz_path, "rt", encoding="utf-8", errors="ignore") as f:
              rows = sum(1 for _ in f) - 1

            rel_path = gz_path.replace("\\","/")
            entry = {
              "ts_utc": ts.isoformat(),
              "file": rel_path,
              "rows": max(rows, 0),
              "sha256": new_hash
            }

            index["snapshots"].insert(0, entry)
            index["snapshots"] = index["snapshots"][:2000]

            os.makedirs("data", exist_ok=True)
            with open(index_path, "w", encoding="utf-8") as f:
              json.dump(index, f, indent=2)

            print("Snapshot saved:", rel_path)
          PY

      - name: Commit & push (if changes)
        run: |
          set -euo pipefail
          if git diff --quiet; then
            echo "No git changes."
            exit 0
          fi
          git config user.name "inventory-bot"
          git config user.email "inventory-bot@users.noreply.github.com"
          git add data/latest data/state data/snapshots data/index.json
          git commit -m "Inventory update (app_ready + snapshot)"
          git push
